{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Font type Recognition using Feed Forward Network\n",
    "\n",
    "* <font size=4 color='green'>MSTC seminar on Deep Learning & Tensorflow</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python -m pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for i in tqdm_notebook(range(100)):\n",
    "    time.sleep(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data: 2790 36x36 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.load('data_with_labels.npz')\n",
    "train = data['arr_0']/255.\n",
    "labels = data['arr_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['arr_0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at some data\n",
    "print(train[0])\n",
    "print(labels[0])\n",
    "\n",
    "# If you have matplotlib installed\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_onehot(labels,nclasses = 5):\n",
    "    '''\n",
    "    Convert labels to \"one-hot\" format.\n",
    "\n",
    "    >>> a = [0,1,2,3]\n",
    "    >>> to_onehot(a,5)\n",
    "    array([[ 1.,  0.,  0.,  0.,  0.],\n",
    "           [ 0.,  1.,  0.,  0.,  0.],\n",
    "           [ 0.,  0.,  1.,  0.,  0.],\n",
    "           [ 0.,  0.,  0.,  1.,  0.]])\n",
    "    '''\n",
    "    outlabels = np.zeros((len(labels),nclasses))\n",
    "    for i,l in enumerate(labels):\n",
    "        outlabels[i,l] = 1\n",
    "    return outlabels\n",
    "\n",
    "onehot = to_onehot(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into training and validation\n",
    "indices = np.random.permutation(train.shape[0])\n",
    "valid_cnt = int(train.shape[0] * 0.1)\n",
    "test_idx,training_idx=indices[:valid_cnt],indices[valid_cnt:]\n",
    "test, train = train[test_idx,:], train[training_idx,:]\n",
    "onehot_test, onehot_train = onehot[test_idx,:], onehot[training_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# These will be inputs\n",
    "## Input pixels, flattened\n",
    "x = tf.placeholder(\"float\", [None, 1296])\n",
    "## Known labels\n",
    "y_ = tf.placeholder(\"float\", [None,5])\n",
    "\n",
    "# Hidden layer 1\n",
    "num_hidden1 = 128\n",
    "W1 = tf.Variable(tf.truncated_normal([1296,num_hidden1],\n",
    "                               stddev=1./math.sqrt(1296)))\n",
    "b1 = tf.Variable(tf.constant(0.1,shape=[num_hidden1]))\n",
    "h1 = tf.sigmoid(tf.matmul(x,W1) + b1)\n",
    "\n",
    "# Hidden Layer 2\n",
    "num_hidden2 = 32\n",
    "W2 = tf.Variable(tf.truncated_normal([num_hidden1,\n",
    "            num_hidden2],stddev=2./math.sqrt(num_hidden1)))\n",
    "b2 = tf.Variable(tf.constant(0.2,shape=[num_hidden2]))\n",
    "h2 = tf.sigmoid(tf.matmul(h1,W2) + b2)\n",
    "\n",
    "# Output Layer\n",
    "W3 = tf.Variable(tf.truncated_normal([num_hidden2, 5],\n",
    "                                   stddev=1./math.sqrt(5)))\n",
    "b3 = tf.Variable(tf.constant(0.1,shape=[5]))\n",
    "\n",
    "# Just initialize\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# Define model\n",
    "y = tf.matmul(h2,W3) + b3\n",
    "\n",
    "### End model specification, begin training code\n",
    "\n",
    "#predictions for our confusion matrix\n",
    "preds=tf.nn.softmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Climb on cross-entropy\n",
    "cross_entropy = tf.reduce_mean(\n",
    "     tf.nn.softmax_cross_entropy_with_logits(y + 1e-50, y_))\n",
    "\n",
    "# How we train\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "# Define accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Actually train\n",
    "epochs = 1000\n",
    "train_acc = np.zeros(epochs//10)\n",
    "test_acc = np.zeros(epochs//10)\n",
    "for i in tqdm(range(epochs), ascii=True):\n",
    "    if i % 10 == 0:  # Record summary data, and the accuracy\n",
    "        # Check accuracy on train set\n",
    "        A = accuracy.eval(feed_dict={x: train.reshape([-1,1296]), y_: onehot_train})\n",
    "        train_acc[i//10] = A\n",
    "\n",
    "        # And now the validation set\n",
    "        A = accuracy.eval(feed_dict={x: test.reshape([-1,1296]), y_: onehot_test})\n",
    "        test_acc[i//10] = A\n",
    "\n",
    "    train_step.run(feed_dict={x: train.reshape([-1,1296]), y_: onehot_train})\n",
    "\n",
    "dnn_test_pred=sess.run(preds,feed_dict={x: test.reshape([-1,1296]), y_: onehot_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check accuracy on train set\n",
    "\n",
    "A = accuracy.eval(feed_dict={x: train.reshape([-1,1296]), y_: onehot_train})\n",
    "print 'Training Accuracy= %s' % A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And now the validation set\n",
    "A = accuracy.eval(feed_dict={x: test.reshape([-1,1296]), y_: onehot_test})\n",
    "print 'Test Accuracy= %s' % A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the accuracy curves\n",
    "plt.plot(train_acc,'b')\n",
    "plt.plot(test_acc,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at the final testing confusion matrix\n",
    "pred = np.argmax(y.eval(feed_dict={x: test.reshape([-1,1296]), y_: onehot_test}), axis = 1)\n",
    "conf = np.zeros([5,5])\n",
    "for p,t in zip(pred,np.argmax(onehot_test,axis=1)):\n",
    "    conf[t,p] += 1\n",
    "\n",
    "plt.matshow(conf)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's look at a subplot of some weights\n",
    "f, plts = plt.subplots(4,8, sharex=True)\n",
    "for i in range(32):\n",
    "    plts[i//8, i%8].matshow(W1.eval()[:,i].reshape([36,36]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine the output weights\n",
    "plt.matshow(W3.eval())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Confusion Matrix</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#packages for confusion matrix\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]\n",
    "\n",
    "for i in dnn_test_pred:\n",
    "    m=np.argmax(i)\n",
    "    a.append(m)\n",
    "    \n",
    "for j in onehot_test:\n",
    "    n=np.argmax(j)\n",
    "    b.append(n)\n",
    "    \n",
    "    \n",
    "prediction=np.asarray(a)\n",
    "label=np.asarray(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names=['0' ,'1' ,'2' ,'3','4'] \n",
    "\n",
    "\n",
    "#Definition of our plotting\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Reds):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix (cm).\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation='horizontal')\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    \n",
    "#Set differences with and without normalization\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "  \n",
    " #some slight changes in order to plot % in the normalize confusion matrix\n",
    "    if normalize:\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, ((\"%.1f\" % (cm[i,j]*100))),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    else:\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, cm[i, j],\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(label, prediction)\n",
    "\n",
    "#Setting print options. Float numbers precision of 2 for our output.\n",
    "np.set_printoptions(precision=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix %')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 1.6",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {
    "0bca62c34ac540139ac348005f32b08c": {
     "views": []
    },
    "10cbceb45c5441c895ab7bc447c8a460": {
     "views": []
    },
    "21f5482c534e40d8af58fa0b8015106c": {
     "views": []
    },
    "29b26ac4b7974aaa8932688cb3e36f26": {
     "views": []
    },
    "37dec577fa8a4e35b3228bc28206f97f": {
     "views": []
    },
    "46cb530c75d74f25b1464d13836a6787": {
     "views": []
    },
    "4e3cfedce439410bb0daa3184562e0e5": {
     "views": []
    },
    "50ded13e18984427b71f06c36142df74": {
     "views": []
    },
    "515adfaf48ed4d02812174a431f9faa0": {
     "views": []
    },
    "bd43d1b298d14a46a2527eb5db1be0d9": {
     "views": []
    },
    "da3f565ae441458fa53054cf671b824d": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "fcf61962d80140e8be45980b145b4979": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
