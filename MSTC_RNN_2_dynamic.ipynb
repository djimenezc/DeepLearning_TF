{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTINUATION TO:\n",
    "## <font color='brown'>Recurrent Neural Networks in Tensorflow I </font>\n",
    "\n",
    "### from:\n",
    "### http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The differences with MSTC_RNN_1 are:\n",
    "\n",
    "* <font color='red' size='3'>**Translating our model to Tensorflow **</font>\n",
    "  \n",
    "* <font color='red' size='3'>**Using dynamic RNN **</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='magenta'>First: dealing with data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font size='3' >**Generate our binary sequences**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font size='3' >**Prepare for feeding data into the graph:** *from raw data to batches*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adapted from \n",
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='magenta'>Second: we will use a rnn_cell in TENSORFLOW's API *tf.nn.rnn_cell.BasicRNNCell*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font size='3' >**Set GLOBAL Configuration Variables**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "num_epochs=1\n",
    "num_steps = 5 # number of truncated backprop steps\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 8\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font size='3' >**Defining the graph model**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* <font size='4'>**Using a dymanic RNN requires rnn_inputs = **</font>\n",
    "<font color='red' size='4'>  A 3-dimnesional tensor of shape [batch_size, num_steps, features]</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dynamic RNN : rnn_inputs = Tensor batch_size x num_steps x no_inputs\n",
    "rnn_inputs = tf.one_hot(x, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Translating our model to a BasicRNNCel in Tensorflowâ€™s API is easy:</font>\n",
    "* **We simply replace two sections by two lines!!!**\n",
    "* **We use:** <font color='red' size='3'>*tf.nn.dynamic_rnn*</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of rnn_cell in TENSORFLOW's API\n",
    "\"\"\"\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(state_size)\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "\n",
    "#cell = tf.nn.rnn_cell.BasicRNNCell(state_size)\n",
    "#rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "\n",
    "#\n",
    "#THAT WAS PREVIOUS Definition of rnn_cell without API\n",
    "\n",
    "#with tf.variable_scope('rnn_cell'):\n",
    "#    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "#    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "#def rnn_cell(rnn_input, state):\n",
    "#    with tf.variable_scope('rnn_cell', reuse=True):\n",
    "#        W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "#        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "#    return tf.tanh(tf.matmul(tf.concat(1, [rnn_input, state]), W) + b)\n",
    "\n",
    "\n",
    "## ALSO the part Adding rnn_cells to graph\n",
    "#state = init_state\n",
    "#rnn_outputs = []\n",
    "#for rnn_input in rnn_inputs:\n",
    "#    state = rnn_cell(rnn_input, state)\n",
    "#    rnn_outputs.append(state)\n",
    "#final_state = rnn_outputs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font size=4 color='green'> Logits and predictions are obtained in a different way. This is shown below.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Predictions, loss, training step FOR DYNAMIC RNN\n",
    "\"\"\"\n",
    "\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "#reshape rnn_outputs and y so we can get the logits in a single matmul\n",
    "rnn_outputs = tf.reshape(rnn_outputs, [-1, state_size])\n",
    "y_reshaped = tf.reshape(y, [-1])\n",
    "\n",
    "logits = tf.matmul(rnn_outputs, W) + b\n",
    "predictions = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font size='3' color='green'>**Loss function and training step are also different**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = tf.reshape(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y_reshaped),\n",
    "                        [batch_size, num_steps])\n",
    "\n",
    "loss_by_timestep = tf.reduce_mean(losses, reduction_indices=0)\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss_by_timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='magenta'>Third: train the network</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font size='3' >**Function to train the network**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        training_losses = []\n",
    "        rnn_outputs_save = []\n",
    "        print(\"Starting for idx...\")\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                rnn_out, training_loss_, training_state, _ = \\\n",
    "                    sess.run([rnn_outputs,loss_by_timestep,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_[-1]\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 100 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "                    rnn_outputs_save.append(rnn_out)\n",
    "\n",
    "    return training_losses, rnn_outputs_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font size='3' >**Train the network**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting for idx...\n",
      "('\\nEPOCH', 0)\n",
      "('Average loss at step', 100, 'for last 100 steps:', 0.69281975030899046)\n",
      "('Average loss at step', 200, 'for last 100 steps:', 0.57533976733684544)\n",
      "('Average loss at step', 300, 'for last 100 steps:', 0.53083031535148617)\n",
      "('Average loss at step', 400, 'for last 100 steps:', 0.49943599700927732)\n",
      "('Average loss at step', 500, 'for last 100 steps:', 0.4910136568546295)\n",
      "('Average loss at step', 600, 'for last 100 steps:', 0.49600539207458494)\n",
      "('Average loss at step', 700, 'for last 100 steps:', 0.4900190931558609)\n",
      "('Average loss at step', 800, 'for last 100 steps:', 0.48864768445491791)\n",
      "('Average loss at step', 900, 'for last 100 steps:', 0.48588787227869035)\n"
     ]
    }
   ],
   "source": [
    "training_losses, rnn_outputs_save  = train_network(num_epochs,num_steps,state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font size='3' >**Plotting training losses**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc41002b550>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc41a0371d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='magenta'>Finally: improve the model playing with hyperparameters num_steps state_size</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font size='3' >**And try to understand your results!**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...see next Notebook MSTC_RNN_3 ... for other RNN types..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 1.6",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}